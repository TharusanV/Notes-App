{"ast":null,"code":"/**\r\n * @typedef {import('micromark-util-types').Construct} Construct\r\n * @typedef {import('micromark-util-types').Resolver} Resolver\r\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\r\n * @typedef {import('micromark-util-types').Token} Token\r\n * @typedef {import('micromark-util-types').State} State\r\n */\n\nimport { ok as assert } from 'uvu/assert';\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { subtokenize } from 'micromark-util-subtokenize';\nimport { codes } from 'micromark-util-symbol/codes.js';\nimport { constants } from 'micromark-util-symbol/constants.js';\nimport { types } from 'micromark-util-symbol/types.js';\n\n/**\r\n * No name because it must not be turned off.\r\n * @type {Construct}\r\n */\nexport const content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent\n};\n\n/** @type {Construct} */\nconst continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n};\n\n/**\r\n * Content is transparent: it’s parsed right now. That way, definitions are also\r\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\r\n *\r\n * @type {Resolver}\r\n */\nfunction resolveContent(events) {\n  subtokenize(events);\n  return events;\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token} */\n  let previous;\n  return start;\n\n  /** @type {State} */\n  function start(code) {\n    assert(code !== codes.eof && !markdownLineEnding(code), 'expected no eof or eol');\n    effects.enter(types.content);\n    previous = effects.enter(types.chunkContent, {\n      contentType: constants.contentTypeContent\n    });\n    return data(code);\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === codes.eof) {\n      return contentEnd(code);\n    }\n    if (markdownLineEnding(code)) {\n      return effects.check(continuationConstruct, contentContinue, contentEnd)(code);\n    }\n\n    // Data.\n    effects.consume(code);\n    return data;\n  }\n\n  /** @type {State} */\n  function contentEnd(code) {\n    effects.exit(types.chunkContent);\n    effects.exit(types.content);\n    return ok(code);\n  }\n\n  /** @type {State} */\n  function contentContinue(code) {\n    assert(markdownLineEnding(code), 'expected eol');\n    effects.consume(code);\n    effects.exit(types.chunkContent);\n    previous.next = effects.enter(types.chunkContent, {\n      contentType: constants.contentTypeContent,\n      previous\n    });\n    previous = previous.next;\n    return data;\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this;\n  return startLookahead;\n\n  /** @type {State} */\n  function startLookahead(code) {\n    assert(markdownLineEnding(code), 'expected a line ending');\n    effects.exit(types.chunkContent);\n    effects.enter(types.lineEnding);\n    effects.consume(code);\n    effects.exit(types.lineEnding);\n    return factorySpace(effects, prefixed, types.linePrefix);\n  }\n\n  /** @type {State} */\n  function prefixed(code) {\n    if (code === codes.eof || markdownLineEnding(code)) {\n      return nok(code);\n    }\n    const tail = self.events[self.events.length - 1];\n    if (!self.parser.constructs.disable.null.includes('codeIndented') && tail && tail[1].type === types.linePrefix && tail[2].sliceSerialize(tail[1], true).length >= constants.tabSize) {\n      return ok(code);\n    }\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code);\n  }\n}","map":{"version":3,"names":["ok","assert","factorySpace","markdownLineEnding","subtokenize","codes","constants","types","content","tokenize","tokenizeContent","resolve","resolveContent","continuationConstruct","tokenizeContinuation","partial","events","effects","previous","start","code","eof","enter","chunkContent","contentType","contentTypeContent","data","contentEnd","check","contentContinue","consume","exit","next","nok","self","startLookahead","lineEnding","prefixed","linePrefix","tail","length","parser","constructs","disable","null","includes","type","sliceSerialize","tabSize","interrupt","flow"],"sources":["E:/0TUser18/Downloads/Projects/Notes App/client/node_modules/micromark-core-commonmark/dev/lib/content.js"],"sourcesContent":["/**\r\n * @typedef {import('micromark-util-types').Construct} Construct\r\n * @typedef {import('micromark-util-types').Resolver} Resolver\r\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\r\n * @typedef {import('micromark-util-types').Token} Token\r\n * @typedef {import('micromark-util-types').State} State\r\n */\r\n\r\nimport {ok as assert} from 'uvu/assert'\r\nimport {factorySpace} from 'micromark-factory-space'\r\nimport {markdownLineEnding} from 'micromark-util-character'\r\nimport {subtokenize} from 'micromark-util-subtokenize'\r\nimport {codes} from 'micromark-util-symbol/codes.js'\r\nimport {constants} from 'micromark-util-symbol/constants.js'\r\nimport {types} from 'micromark-util-symbol/types.js'\r\n\r\n/**\r\n * No name because it must not be turned off.\r\n * @type {Construct}\r\n */\r\nexport const content = {tokenize: tokenizeContent, resolve: resolveContent}\r\n\r\n/** @type {Construct} */\r\nconst continuationConstruct = {tokenize: tokenizeContinuation, partial: true}\r\n\r\n/**\r\n * Content is transparent: it’s parsed right now. That way, definitions are also\r\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\r\n *\r\n * @type {Resolver}\r\n */\r\nfunction resolveContent(events) {\r\n  subtokenize(events)\r\n  return events\r\n}\r\n\r\n/** @type {Tokenizer} */\r\nfunction tokenizeContent(effects, ok) {\r\n  /** @type {Token} */\r\n  let previous\r\n\r\n  return start\r\n\r\n  /** @type {State} */\r\n  function start(code) {\r\n    assert(\r\n      code !== codes.eof && !markdownLineEnding(code),\r\n      'expected no eof or eol'\r\n    )\r\n\r\n    effects.enter(types.content)\r\n    previous = effects.enter(types.chunkContent, {\r\n      contentType: constants.contentTypeContent\r\n    })\r\n    return data(code)\r\n  }\r\n\r\n  /** @type {State} */\r\n  function data(code) {\r\n    if (code === codes.eof) {\r\n      return contentEnd(code)\r\n    }\r\n\r\n    if (markdownLineEnding(code)) {\r\n      return effects.check(\r\n        continuationConstruct,\r\n        contentContinue,\r\n        contentEnd\r\n      )(code)\r\n    }\r\n\r\n    // Data.\r\n    effects.consume(code)\r\n    return data\r\n  }\r\n\r\n  /** @type {State} */\r\n  function contentEnd(code) {\r\n    effects.exit(types.chunkContent)\r\n    effects.exit(types.content)\r\n    return ok(code)\r\n  }\r\n\r\n  /** @type {State} */\r\n  function contentContinue(code) {\r\n    assert(markdownLineEnding(code), 'expected eol')\r\n    effects.consume(code)\r\n    effects.exit(types.chunkContent)\r\n    previous.next = effects.enter(types.chunkContent, {\r\n      contentType: constants.contentTypeContent,\r\n      previous\r\n    })\r\n    previous = previous.next\r\n    return data\r\n  }\r\n}\r\n\r\n/** @type {Tokenizer} */\r\nfunction tokenizeContinuation(effects, ok, nok) {\r\n  const self = this\r\n\r\n  return startLookahead\r\n\r\n  /** @type {State} */\r\n  function startLookahead(code) {\r\n    assert(markdownLineEnding(code), 'expected a line ending')\r\n    effects.exit(types.chunkContent)\r\n    effects.enter(types.lineEnding)\r\n    effects.consume(code)\r\n    effects.exit(types.lineEnding)\r\n    return factorySpace(effects, prefixed, types.linePrefix)\r\n  }\r\n\r\n  /** @type {State} */\r\n  function prefixed(code) {\r\n    if (code === codes.eof || markdownLineEnding(code)) {\r\n      return nok(code)\r\n    }\r\n\r\n    const tail = self.events[self.events.length - 1]\r\n\r\n    if (\r\n      !self.parser.constructs.disable.null.includes('codeIndented') &&\r\n      tail &&\r\n      tail[1].type === types.linePrefix &&\r\n      tail[2].sliceSerialize(tail[1], true).length >= constants.tabSize\r\n    ) {\r\n      return ok(code)\r\n    }\r\n\r\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code)\r\n  }\r\n}\r\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,SAAQA,EAAE,IAAIC,MAAM,QAAO,YAAY;AACvC,SAAQC,YAAY,QAAO,yBAAyB;AACpD,SAAQC,kBAAkB,QAAO,0BAA0B;AAC3D,SAAQC,WAAW,QAAO,4BAA4B;AACtD,SAAQC,KAAK,QAAO,gCAAgC;AACpD,SAAQC,SAAS,QAAO,oCAAoC;AAC5D,SAAQC,KAAK,QAAO,gCAAgC;;AAEpD;AACA;AACA;AACA;AACA,OAAO,MAAMC,OAAO,GAAG;EAACC,QAAQ,EAAEC,eAAe;EAAEC,OAAO,EAAEC;AAAc,CAAC;;AAE3E;AACA,MAAMC,qBAAqB,GAAG;EAACJ,QAAQ,EAAEK,oBAAoB;EAAEC,OAAO,EAAE;AAAI,CAAC;;AAE7E;AACA;AACA;AACA;AACA;AACA;AACA,SAASH,cAAc,CAACI,MAAM,EAAE;EAC9BZ,WAAW,CAACY,MAAM,CAAC;EACnB,OAAOA,MAAM;AACf;;AAEA;AACA,SAASN,eAAe,CAACO,OAAO,EAAEjB,EAAE,EAAE;EACpC;EACA,IAAIkB,QAAQ;EAEZ,OAAOC,KAAK;;EAEZ;EACA,SAASA,KAAK,CAACC,IAAI,EAAE;IACnBnB,MAAM,CACJmB,IAAI,KAAKf,KAAK,CAACgB,GAAG,IAAI,CAAClB,kBAAkB,CAACiB,IAAI,CAAC,EAC/C,wBAAwB,CACzB;IAEDH,OAAO,CAACK,KAAK,CAACf,KAAK,CAACC,OAAO,CAAC;IAC5BU,QAAQ,GAAGD,OAAO,CAACK,KAAK,CAACf,KAAK,CAACgB,YAAY,EAAE;MAC3CC,WAAW,EAAElB,SAAS,CAACmB;IACzB,CAAC,CAAC;IACF,OAAOC,IAAI,CAACN,IAAI,CAAC;EACnB;;EAEA;EACA,SAASM,IAAI,CAACN,IAAI,EAAE;IAClB,IAAIA,IAAI,KAAKf,KAAK,CAACgB,GAAG,EAAE;MACtB,OAAOM,UAAU,CAACP,IAAI,CAAC;IACzB;IAEA,IAAIjB,kBAAkB,CAACiB,IAAI,CAAC,EAAE;MAC5B,OAAOH,OAAO,CAACW,KAAK,CAClBf,qBAAqB,EACrBgB,eAAe,EACfF,UAAU,CACX,CAACP,IAAI,CAAC;IACT;;IAEA;IACAH,OAAO,CAACa,OAAO,CAACV,IAAI,CAAC;IACrB,OAAOM,IAAI;EACb;;EAEA;EACA,SAASC,UAAU,CAACP,IAAI,EAAE;IACxBH,OAAO,CAACc,IAAI,CAACxB,KAAK,CAACgB,YAAY,CAAC;IAChCN,OAAO,CAACc,IAAI,CAACxB,KAAK,CAACC,OAAO,CAAC;IAC3B,OAAOR,EAAE,CAACoB,IAAI,CAAC;EACjB;;EAEA;EACA,SAASS,eAAe,CAACT,IAAI,EAAE;IAC7BnB,MAAM,CAACE,kBAAkB,CAACiB,IAAI,CAAC,EAAE,cAAc,CAAC;IAChDH,OAAO,CAACa,OAAO,CAACV,IAAI,CAAC;IACrBH,OAAO,CAACc,IAAI,CAACxB,KAAK,CAACgB,YAAY,CAAC;IAChCL,QAAQ,CAACc,IAAI,GAAGf,OAAO,CAACK,KAAK,CAACf,KAAK,CAACgB,YAAY,EAAE;MAChDC,WAAW,EAAElB,SAAS,CAACmB,kBAAkB;MACzCP;IACF,CAAC,CAAC;IACFA,QAAQ,GAAGA,QAAQ,CAACc,IAAI;IACxB,OAAON,IAAI;EACb;AACF;;AAEA;AACA,SAASZ,oBAAoB,CAACG,OAAO,EAAEjB,EAAE,EAAEiC,GAAG,EAAE;EAC9C,MAAMC,IAAI,GAAG,IAAI;EAEjB,OAAOC,cAAc;;EAErB;EACA,SAASA,cAAc,CAACf,IAAI,EAAE;IAC5BnB,MAAM,CAACE,kBAAkB,CAACiB,IAAI,CAAC,EAAE,wBAAwB,CAAC;IAC1DH,OAAO,CAACc,IAAI,CAACxB,KAAK,CAACgB,YAAY,CAAC;IAChCN,OAAO,CAACK,KAAK,CAACf,KAAK,CAAC6B,UAAU,CAAC;IAC/BnB,OAAO,CAACa,OAAO,CAACV,IAAI,CAAC;IACrBH,OAAO,CAACc,IAAI,CAACxB,KAAK,CAAC6B,UAAU,CAAC;IAC9B,OAAOlC,YAAY,CAACe,OAAO,EAAEoB,QAAQ,EAAE9B,KAAK,CAAC+B,UAAU,CAAC;EAC1D;;EAEA;EACA,SAASD,QAAQ,CAACjB,IAAI,EAAE;IACtB,IAAIA,IAAI,KAAKf,KAAK,CAACgB,GAAG,IAAIlB,kBAAkB,CAACiB,IAAI,CAAC,EAAE;MAClD,OAAOa,GAAG,CAACb,IAAI,CAAC;IAClB;IAEA,MAAMmB,IAAI,GAAGL,IAAI,CAAClB,MAAM,CAACkB,IAAI,CAAClB,MAAM,CAACwB,MAAM,GAAG,CAAC,CAAC;IAEhD,IACE,CAACN,IAAI,CAACO,MAAM,CAACC,UAAU,CAACC,OAAO,CAACC,IAAI,CAACC,QAAQ,CAAC,cAAc,CAAC,IAC7DN,IAAI,IACJA,IAAI,CAAC,CAAC,CAAC,CAACO,IAAI,KAAKvC,KAAK,CAAC+B,UAAU,IACjCC,IAAI,CAAC,CAAC,CAAC,CAACQ,cAAc,CAACR,IAAI,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,CAACC,MAAM,IAAIlC,SAAS,CAAC0C,OAAO,EACjE;MACA,OAAOhD,EAAE,CAACoB,IAAI,CAAC;IACjB;IAEA,OAAOH,OAAO,CAACgC,SAAS,CAACf,IAAI,CAACO,MAAM,CAACC,UAAU,CAACQ,IAAI,EAAEjB,GAAG,EAAEjC,EAAE,CAAC,CAACoB,IAAI,CAAC;EACtE;AACF"},"metadata":{},"sourceType":"module"}